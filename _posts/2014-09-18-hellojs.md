---
layout: post
title: "Hello.js, ineed"
author: "Alex Young"
categories:
- libraries
- apis
- parsing
---

###Hello.js

Andrew Dodson sent in [hello.js](http://adodson.com/hello.js/#hellojs) (GitHub: [MrSwitch / hello.js](https://github.com/MrSwitch/hello.js), License: _MIT_, npm: [hellojs](https://www.npmjs.org/package/hellojs)), a client-side API wrapper for OAuth2-based REST APIs.  It presents a unified API that normalizes paths and responses for Google Data Services, Facebook Graph and Windows Live Connect.

One of the advantages of hello.js is it's modular.  There are [hello.js modules](http://adodson.com/hello.js/modules.html#hellojs-already-has-you-connected) for Dropbox, LinkedIn, SoundCloud, and Yahoo.

The module API allows you to define things like jsonp functions, so it should be flexible enough to handle a lot of modern services.

[HelloJS](https://news.ycombinator.com/item?id=8300112) has been on Hacker News, with a discussion on security, and [endorsements](https://news.ycombinator.com/item?id=8300751) from users:

> HelloJS is great. I've used it in my last project. It just works. It's well tested, and well documented. There's very little option twiddling required. It just worked seamlessly when I was trying to setup Twitter, Google, LinkedIn and Facebook OAuth logins.

###ineed

Ivan Nikulin wrote in to say [parse5 has a new SAX-style HTML parser](https://github.com/inikulin/parse5#class-simpleapiparser) which powers the [ineed](https://github.com/inikulin/ineed) project:

> `ineed` allows you collect useful data from web pages using simple and nice API. Let's collect images, hyperlinks, scripts and stylesheets from www.google.com:

{% highlight javascript %}
var ineed = require('ineed');

ineed.collect.images.hyperlinks.scripts.stylesheets.from('http://www.google.com',
  function (err, response, result) {
    console.log(result);
  });
{% endhighlight %}

Internally, `ineed` uses streams of HTML tokens so it doesn't have to spend time building and traversing a DOM tree.  It seems like an ideal way to handle lots of otherwise awkward scraping tasks.
